{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "55b1a9a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b1a9a4",
        "outputId": "7fabc623-6490-409c-c087-f24cb0dbd036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.21.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.21.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.8.7)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.6.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.3.71)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.3.27)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.3.6)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (1.11.0.post1)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (2.1.8)\n",
            "Requirement already satisfied: langchain_anthropic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.3.17)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.3.1)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.3.28)\n",
            "Requirement already satisfied: grandalf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.8)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (5.8.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (6.0.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.5.4)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.12.52)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.5.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->-r requirements.txt (line 7)) (0.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (80.9.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 9)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 9)) (1.48.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.33.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 13)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 13)) (3.6.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core->-r requirements.txt (line 14)) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core->-r requirements.txt (line 14)) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->-r requirements.txt (line 14)) (1.33)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (3.12.14)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 15)) (0.4.1)\n",
            "Requirement already satisfied: groq<1,>=0.29.0 in /usr/local/lib/python3.11/dist-packages (from langchain_groq->-r requirements.txt (line 16)) (0.30.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 17)) (4.53.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai->-r requirements.txt (line 19)) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai->-r requirements.txt (line 19)) (0.6.18)\n",
            "Requirement already satisfied: anthropic<1,>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from langchain_anthropic->-r requirements.txt (line 20)) (0.59.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->-r requirements.txt (line 22)) (1.97.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->-r requirements.txt (line 22)) (0.9.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf->-r requirements.txt (line 23)) (3.2.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client->-r requirements.txt (line 25)) (2025.7.14)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client->-r requirements.txt (line 25)) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client->-r requirements.txt (line 25)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client->-r requirements.txt (line 25)) (2.5.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r requirements.txt (line 26)) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r requirements.txt (line 26)) (0.5.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph->-r requirements.txt (line 26)) (0.1.74)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.4.12)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.4.4)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.52.post1 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.12.52.post1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.7.10)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.5.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.4.11)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirements.txt (line 27)) (3.9.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 15)) (1.20.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 15)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 15)) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (1.26.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets->-r requirements.txt (line 5)) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 9)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 9)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 9)) (0.26.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community->-r requirements.txt (line 15)) (0.3.8)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r requirements.txt (line 26)) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->-r requirements.txt (line 26)) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core->-r requirements.txt (line 14)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core->-r requirements.txt (line 14)) (0.23.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (2.2.0)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.0.8)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.2.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.32 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 27)) (0.1.32)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index->-r requirements.txt (line 27)) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index->-r requirements.txt (line 27)) (0.7.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index->-r requirements.txt (line 27)) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 27)) (0.6.43)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 27)) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 10)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 10)) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 15)) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 15)) (3.2.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 11)) (0.1.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 17)) (0.5.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 11)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 11)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 11)) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 11)) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index->-r requirements.txt (line 27)) (2.7)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.57.0->langchain_anthropic->-r requirements.txt (line 20)) (0.16.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 11)) (1.2.1)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (0.3.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.43 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 27)) (0.6.43)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 11)) (2.19.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 15)) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 11)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai->-r requirements.txt (line 19)) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.52.post1->llama-index->-r requirements.txt (line 27)) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Literal\n",
        "from langchain_core.tools import tool\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import MessagesState, StateGraph,START,END\n",
        "from langgraph.types import Command\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Image, display\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import Annotated\n",
        "from langchain_experimental.utilities import PythonREPL"
      ],
      "metadata": {
        "id": "gBbXBPkhGan9"
      },
      "id": "gBbXBPkhGan9",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4zsKk5oTGTmv"
      },
      "id": "4zsKk5oTGTmv"
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "id": "kFScRZapJIdT",
        "outputId": "b64141f1-95b4-4a16-e932-47778d1a0ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kFScRZapJIdT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "Cjbw4BlwJEeX"
      },
      "id": "Cjbw4BlwJEeX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "cdf1069e",
      "metadata": {
        "id": "cdf1069e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d60cb9d8",
      "metadata": {
        "id": "d60cb9d8"
      },
      "outputs": [],
      "source": [
        "#openai_model=ChatOpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\", api_key =api_key)"
      ],
      "metadata": {
        "id": "1wZ3VyHWH6ue"
      },
      "id": "1wZ3VyHWH6ue",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b50a1bdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b50a1bdb",
        "outputId": "eb078336-1ae6-4d3e-b5c3-0c7073ef5500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 4, 'total_tokens': 20, 'completion_time': 0.081133427, 'prompt_time': 6.7428e-05, 'queue_time': 0.201965435, 'total_time': 0.081200855}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fa4cf76d-e047-4dd0-828e-7e0d2dc27abf-0', usage_metadata={'input_tokens': 4, 'output_tokens': 16, 'total_tokens': 20})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "groq_model.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c4564686",
      "metadata": {
        "id": "c4564686"
      },
      "outputs": [],
      "source": [
        "def add_numbers(state):\n",
        "    result=state[\"num1\"]+state[\"num2\"]\n",
        "    print(f\"additional result: {result}\")\n",
        "    return Command(goto=\"multiply\",update={\"sum\":result})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "549d22e5",
      "metadata": {
        "id": "549d22e5"
      },
      "outputs": [],
      "source": [
        "state={\"num1\":1, \"num2\":2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "75f91859",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75f91859",
        "outputId": "5ef6d45f-2d51-4294-b8db-7ed9e5728467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "additional result: 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Command(update={'sum': 3}, goto='multiply')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "add_numbers(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "72ae2dad",
      "metadata": {
        "id": "72ae2dad"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def transfer_to_multiplication_expert():\n",
        "    \"\"\"Ask multiplication agent for help\"\"\"\n",
        "    return\n",
        "\n",
        "@tool\n",
        "def transfer_to_addition_expert():\n",
        "    \"\"\"Ask addition agent for help\"\"\"\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e9483269",
      "metadata": {
        "id": "e9483269"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_with_tool=groq_model.bind_tools([transfer_to_multiplication_expert,transfer_to_addition_expert])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "34dedba2",
      "metadata": {
        "id": "34dedba2"
      },
      "outputs": [],
      "source": [
        "ai_message=model_with_tool.invoke(\"hi how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a78cb865",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a78cb865",
        "outputId": "7a3fc05c-80b4-4ddf-d2d1-47d609465858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ai_message.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6f126e76",
      "metadata": {
        "id": "6f126e76"
      },
      "outputs": [],
      "source": [
        "\n",
        "ai_message=model_with_tool.invoke(\"what's (3 + 5) * 12. Provide me the output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "72fdae54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72fdae54",
        "outputId": "f4c2021a-61e4-4412-ebe3-d28a0810bf5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The result of (3 + 5) * 12 is 96.\\n\\nStep-by-step explanation:\\n1. Calculate the addition inside the parentheses: 3 + 5 = 8.\\n2. Multiply the result by 12: 8 * 12 = 96.\\n\\nAnswer: 96', additional_kwargs={'reasoning_content': \"Okay, so I've got this math problem here: (3 + 5) * 12. Hmm, let me break it down step by step. First, I remember that in math problems, especially when there are parentheses, I should do what's inside them first. So, 3 plus 5. That's straightforward, right? 3 plus 5 equals 8. So now, the problem simplifies to 8 multiplied by 12.\\n\\nWait, but I'm not entirely sure if I should handle the addition first. Maybe I should double-check the order of operations. I think it's parentheses, exponents, multiplication and division, and then addition and subtraction, often remembered by PEMDAS. So yes, the addition inside the parentheses comes first. That part seems right.\\n\\nNow, moving on to the multiplication: 8 times 12. I'm a bit rusty on my multiplication tables, so let me think. 8 times 10 is 80, and 8 times 2 is 16. So if I add those together, 80 plus 16 equals 96. So, 8 multiplied by 12 should be 96.\\n\\nBut wait, let me make sure I didn't make a mistake. Maybe I should try another way to confirm. Let's see, 12 times 8. I know that 12 times 10 is 120, and 12 times (-2) is -24. Wait, that doesn't make sense because 8 is positive. Maybe I should think of it as 12 times 8, which is the same as 8 times 12. Yeah, that's commutative property. So, 12 times 8 is also 96. That matches what I had before, so I must be right.\\n\\nAlternatively, I could add 12 eight times: 12 + 12 is 24, plus another 12 is 36, then 48, 60, 72, 84, and finally 96. That's adding 12 eight times, which also gives me 96. So, three different methods all pointing to the same answer. That makes me confident that 8 times 12 is indeed 96.\\n\\nSo putting it all together, (3 + 5) is 8, and 8 times 12 is 96. Therefore, the final answer should be 96. I think that's it. No mistakes there.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 565, 'prompt_tokens': 162, 'total_tokens': 727, 'completion_time': 2.158039173, 'prompt_time': 0.010166284, 'queue_time': 0.212150648, 'total_time': 2.168205457}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9502a862-a368-4fb2-93f4-e22fdfe8da15-0', usage_metadata={'input_tokens': 162, 'output_tokens': 565, 'total_tokens': 727})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "ai_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "97e420bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e420bf",
        "outputId": "4a457fa9-3e07-416b-e521-82bb1f826ec2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "ai_message.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def additional_expert1(state:MessagesState)-> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
        "\n",
        "   if 1 > 0:\n",
        "        return Command(\n",
        "            goto=\"multiplication_expert\", update={\"messages\": [\"\"]}\n",
        "        )\n",
        "        return {\"messages\": [\"\"]}"
      ],
      "metadata": {
        "id": "CihEQN4BLukQ"
      },
      "id": "CihEQN4BLukQ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d0c34824",
      "metadata": {
        "id": "d0c34824"
      },
      "outputs": [],
      "source": [
        "def additional_expert(state:MessagesState)-> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
        "    print(\"*******************addition expert called\")\n",
        "    system_prompt = (\n",
        "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
        "        \"Always do your portion of calculation before the handoff.\"\n",
        "    )\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
        "\n",
        "\n",
        "    ai_msg = groq_model.bind_tools([transfer_to_multiplication_expert]).invoke(messages)\n",
        "\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0:\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "\n",
        "        return Command(\n",
        "            goto=\"multiplication_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
        "        )\n",
        "    return {\"messages\": [ai_msg]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "00aa29cc",
      "metadata": {
        "id": "00aa29cc"
      },
      "outputs": [],
      "source": [
        "def multiplication_expert(state:MessagesState)-> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
        "    print(\"*******************multiplication_expert expert called********************************\")\n",
        "    system_prompt = (\n",
        "        \"You are a multiplication expert, you can ask an addition expert for help with addition. \"\n",
        "        \"Always do your portion of calculation before the handoff.\"\n",
        "    )\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
        "\n",
        "    ai_msg = groq_model.bind_tools([transfer_to_addition_expert]).invoke(messages)\n",
        "\n",
        "    if len(ai_msg.tool_calls) > 0:\n",
        "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
        "        tool_msg = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": \"Successfully transferred\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "        return Command(goto=\"additional_expert1\", update={\"messages\": [ai_msg, tool_msg]})\n",
        "    return {\"messages\": [ai_msg]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e1147963",
      "metadata": {
        "id": "e1147963"
      },
      "outputs": [],
      "source": [
        "graph=StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNjj8TTjM_Ic"
      },
      "id": "ZNjj8TTjM_Ic",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3acd23e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3acd23e6",
        "outputId": "75129993-8dde-4db1-b727-71998c54d1b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d26f4490190>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#graph.add_node(\"additional_expert1\",additional_expert1)\n",
        "graph.add_node(\"additional_expert\",additional_expert)\n",
        "graph.add_node(\"multiplication_expert\",multiplication_expert)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a41792d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a41792d6",
        "outputId": "521d2d17-3e19-49b2-ecc9-c04efe22ceea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d26f4490190>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#graph.add_edge(START, \"additional_expert1\")\n",
        "graph.add_edge(START, \"additional_expert\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.nodes"
      ],
      "metadata": {
        "id": "s0Q5lmaBNiXy",
        "outputId": "01a3ca4e-629c-46f3-ccdf-4b106366640b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "s0Q5lmaBNiXy",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'additional_expert': StateNodeSpec(runnable=additional_expert(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'langgraph.graph.message.MessagesState'>, retry_policy=None, cache_policy=None, ends=('multiplication_expert', '__end__'), defer=False),\n",
              " 'multiplication_expert': StateNodeSpec(runnable=multiplication_expert(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'langgraph.graph.message.MessagesState'>, retry_policy=None, cache_policy=None, ends=('additional_expert', '__end__'), defer=False)}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e7d83d54",
      "metadata": {
        "id": "e7d83d54"
      },
      "outputs": [],
      "source": [
        "app=graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a93fae17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "a93fae17",
        "outputId": "7f027e89-53ff-45ba-d45e-9e90564c1751"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAFNCAIAAAB0Zu9LAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcFMf7x+d6pR+9SbGAiKDYG4hdikHFimjsJRqDxkRjiRqNX1tirLF3Yo2xRFHBrrEgTUVBmiC9Xe/3+2P9EYInHHi7e3s37xd/3G2Z+dzxudlnZ2eeIWk0GgCBEAoy3gIgkGYDXQshHtC1EOIBXQshHtC1EOIBXQshHlS8BTRGZbFcWKMU8ZUyiVouUeMtp2moNBKFSmKbUzjmVGsHBosLGwVUIBlgf23Ba0lOujD3hcjZmyUTqdjmVEtbmlplcDo/hsYgIz8zMV8lk6ioNLJHe453ANeCR8NbmlFhWK5990by4GKFnSuD58zwaM/hWhr0paBJSvKkuS9EVaVyNpfSM4zHYMOmVz8YkGtvxpcJqhW9wnm2Lgy8teiZFw/5Dy5VdB1s07GvBd5ajAGDcC2/UnHifwURs5ydPJh4a0GR50k1ZYXSwTEOeAshPPi7VipUn/qlYPy37lQ6CV8lGPAmWZD5WBAxywlvIcQGZ9dWFsuvHCyOWeqOowaMyUkXPbleNeYbV7yFEBic7w9ObiwwKcsCADw7cPx7W9w4WYq3EAKDZ1t79XBJtyE2Vvam2Cv07GY1g0Xx62mOtxBCgltb++oxn0onmaZlAQCdQ61unSnDWwVRwc21Dy5V9grn4VW7IdAzzObBxUq8VRASfFz78hG/Y19LFpeCS+0GQqf+VpUlMkI8qTY08HFt5lM+xl2z2dnZYWFhLTjxjz/+WLlyJQqKAACAxaW8TReiVLgRg4NrZRJ1xXu5kxcLy0ozMjJaduKLFy/0reVfPNpzc1+I0CvfWMHBtQWZYr8eaN0719bW/u9//4uIiOjbt++sWbP++usvAMCOHTvWrl1bUlISFBQUHx8PALh79+4PP/wwbNiwPn36zJ49+9mzZ8jpJ06cGDJkyK1bt7p167Z169apU6deuXLl8uXLQUFB2dnZelfr2YEjrFEC/J9OEgwchqdUlchpDLR+LWvWrKmoqFi6dGmrVq1OnTq1Zs0aT0/PuXPnqlSqhISES5cuAQDEYvGyZct69uy5evVqAEBCQsLChQsvXLhgZWVFp9PFYvGRI0fWrFnj4+OzcOHCyZMnu7u7//jjj2ioJZGARKgS1CjNrIg9TghjcPiyxAKlnRtaQW1ycvKUKVO6d+8OAJg/f/6AAQOsra0bHMNms+Pj49lstqWlJQCgXbt2586dS01NDQ4OplAoYrF4zpw5QUFBKClsKMacKuJD1zYPHL4skUDFNkOr9yAgIODw4cOVlZVBQUHdu3f39fXVrkEk2r59e3JyckVFBbKlurq6bu+nzkIDjjlFVKvCrDrjAIe4lkwCZApaA2VWrVo1fvz4Bw8efP311wMGDNi9e7dSqWxwTHFx8bRp09Rq9fr16x89enT//v0GB9DpdJTkfQyVRoZxbXPBoa1lsCmi2oZO0hfm5uZffvnllClTUlNTExMT9+3bZ2FhMW7cuPrHXLt2TaFQrFq1islkAgBqampQEqMLgioF29yk+61bAA6uZZtTxAJUrok1NTXXrl0bMWIEg8EICAgICAh49erV69evPz7M3NwcsSwA4MaNG2iI0RERX8mBrm0mOEQIVnZ0tRKViyKFQtm1a9eSJUvS0tKqqqouXbqUmZnZsWNHAICbm1tFRcXt27cLCgratGlTUVHx559/KpXK+/fvp6SkcLnckpISrWW6urq+fPny6dOn9QNfPcK1pJlZmuhgjBZDWbVqFcZVss2oN/8o6xRipfeSGQyGv79/QkLCwYMHjx49WlhYOHPmzMjISBKJxOPxXr58eejQISsrq+joaKVSeeLEiW3btvH5/KVLl4pEoqNHj/L5fGtr67t3706bNo1M/vB7trKyunPnzokTJ3r27OnkpOfR3HkvxRXvZW2DzPRbrNGDz0jF07+86/uFrb27Mc+30YWk02W2zgy/nnAyWfPAZxxC287mxblSXKo2KMR8lYcfF28VxAOfzm3/Pha7l7z162nxqbliCQkJ69at07rL2tq6qqpK665Ro0bNmzdPr0r/ZcCAAR93oiFoNBoSSfsHOXnypKOjo9Zd6fdruZZUeCvWAnCby5B2t7amXN43ylbrXrFY/KkOKalUWnf73wAOh2NhgdbV9v3795/aJZPJGAzts+Ht7OyoVO1Nw57v3365ygO9h9tGDJ4zcC7vLw4ebWeajU3a/VqVQhMYbIm3EEKC5w89dKzdyY35OArAi7yX4vyXImjZFoOna5kcypBJjmd+LcRRA/ZUlyqSTpeFT4cpEVoO/lk8asoUN+JLR813wVcGNrzPkSadKh2/xP0TN28QncDftQCA928llw8Uj/nGzdzGmAfsvX4qzHhUM3KeSfw+UcUgXAsAkInVN+JLGUxyjzCe8d2f5b0QPbhc6enH6T7MBm8txoChuBYh84ngwaWKdl3MHdyZnn4cQPDLqKBamZshKnsnk4qVPcN41g7YDYA0bgzLtQhvngmyU4U5GSL/3hYqpYZtTrWwoWmIMAqVQiWJ+Sok67JYoKouk3v6cdp0MnNoZerPrvWLIbq2joJMiaBGIeIrFVK1RKTnvAFpaWmOjo62ttofc7QMBotMIgEkw72NI4PnBBtXVDDoux+3diwA0JqAfi35Wif/4cHB7VEqH4Ie8HEihHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHiYrmsZDMan0tJDDBzTda1MJjPkvDuQRjBd10KIC3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIB3QthHhA10KIh0Gv7YgGnTp1Ql6QyWSNRoN8fAcHhytXruAtDaIrJtfWent7I5YFAJBIJDKZTKPRoqOj8dYFaQYm59pJkyaxWP9Z5dTNzS0qKgo/RZBmY3KuDQsLc3V1rXtLpVKHDRtmbm6OqyhI8zA51wIAYmJiGAwG8trNzW3UqFF4K4I0D1N07fDhw5HmlkKhDB061MzMDG9FkOZhiq4FAIwbN47BYLRq1QpGtESE2uQRlcXyyvcyEV+JiR6McDPvG+iR5evrm5OsBqAabzl6g8agmFlRbZzoXIum/7PEpbH+WrUaXNz7XipSm9vQmGxj/haMBgabXFogoVBILq1ZnUIs8ZaDFp90rVoFzu0o8utp5dyajbkqyOdy/0KZgzsjoJ8F3kJQ4ZNx7V+/F3XoDS1LVHpF2hVmSd4kC/EWggraXVucIyWTyU5e0LIEplOoTdq9GrxVoIJ211YUy9jmMJAlNmbWtPJCmVJhhONMtLtWLFCxuNC1hMfcmiaqNarOH4RPxLUaYGpjwYwSlco4/4km+pQBQmigayHEA7oWQjygayHEA7oWQjygayHEA7oWQjygayHEA7oWQjygayHEA7oWQjxwcO2kySN/27Gp8V1vsjJDQoNevEhrcMDpM8cHDemBhqqcnOyQ0KD09BQ0CofoFwNta22seZNipvF4doifxo4PQ7b7+nSYOGEq3upwoP6XADHQ4Yg2Nrwpk2chr19lZtRtb9/ev317f/x04Ub9LwGiN9fm5r796+KZZ8mPy8pK3N08wsNHhg3/AtmVl5fz84aVBe/yAgKCYiZOq3/Wp3a9ycqcOWvi9m0HHj66e/zEQQBASGjQvLmL1GrV3n3bE64+RA67f//24SO/5+XnWFlZe3m1Wbjge1tbOwBARGTI1Klzq6oqjhzdx+FwunbpOW/uImtrm8Z16siVvy9cvHQuL++tp2fr/iGDR0aNBQAUFORNmzFu1owFUVFjAQAikWhCTOTAAcPmzvnmu6ULWEyWq6v7H6eOqtVqL8/W3y5e6enpDQBQKpV7921/9M+9iooyf/9OIyKju3XtidQSHhE8ZfKsW3dupKenRI+eeOr0MeRLWLF8fUjwwM/+dxEbvUUIv23f+PTZP18v+G79ul+HDo3cvOWnJ08fAQAUCsWS77+ytbU/uP/0tC/nnjhxsLqqEjmlkV11TJs6d+yYSfb2Dkk3nyL+qOPps39WrFo8eHD46T/+/mHpT8XFRdt++x+yi85gnIw/xGAw/7qQdOjAmdS05CNH9zauU0euX7+ycdOadm19Tx6/OGXyrFOnj+7ctRUA4ObWKmbitP0Hd9bUVAMA9u3fzuVwZ0z/CgBAp9GTnz+hUmnX/n5w6OAZC0ur5SsXIcOXt/6y/tz5+JFR406euNS7V/DyFXH37t9CKqLR6efOx7du3W7Txp0zpn9V9yVAy+rTtStXbti4YUenwC6BAUEjIke39m77+PEDAMCdu4llZaVz58TZ2zt4enrPm7tIKPowBa+RXbpw4OCufn1DR0aNtbCw7NAhYNbMr+/dv5WTk40kS3R1cR8/brIZ14zHs+3cudubrMzGderIxcvn/P0DF8xfYmlpFdS5W+ykGefOx9fW1gAAxo2NtbNz2LXnl/z83EuXzy9dupZGoyFi5HLZ+HGTAQDOTi6xk2a8f1/48mW6VCpNuH55/LjJEeEjzc3Mhw8bERIy6MiRD78uCoXCs7X7au6izp26UiiU5vwrjB+9RQgatfr02eOPHz8oLCxAtri7ewAAioreMZlMBwdHZKO9vYONDQ953cguXcjJyeofMqjubbu2vkj8h1x827TxqdtlZmYuFAoa16kLSqXy5cv0ybEz67YEBnZRqVTp6Sm9ewdTqdTFi1bMnTf51auMMdExvj5+dYd5eHhTqR++ahcXNwBAfkGuQqFQKpVdgv7tEgno2Dkh4bJIJOJwOACANq19AEQb+nGtSqVa8t1XGo1m5oz5gQFdOBzOnHmTkV18fi2Hw61/MJPJanJXkwiFQplMxmAw67aw2RwAgFQiQd6SSKRm6dQFqVSqUqn2H9i5/8DO+tura6qQF74+fl2Cuj95+qhnj77/+Vz1dLKYLACAWCwSigQAgK8WNOwSqaqqQFxLp9N112ZS6Me1r1+/fJOVuXnTrk6BXZAtdW2bubmFXCarf7BYLGpyV5MwmUwAgFQqaXCudaOtdSM6dYHL5TKZzCGDw/v2Da2/3dnpQ2rRtLTnaenPe/bsu/WX9bt3Ha27sovqRT4SqQT5fVpb8wAAcd8sc3Z2rV8a0t8HaQT9xLVIYMezsUXe5uRkv3uXj7x2sHcUCAX5+bnI21eZL6qrq5rc1SRUKrVtG5/6jyGQ154e3i3TqSOenq0lUklgQBDy197Xn2dja2dnDwCQyWTrfl4+KWb64rjlJSXvkbt+hLc5WUjVAICsrEwAgEcrL1dXdzqdTqFQ6kpzd/No5e7ZICk05GP049pWHl4kEun0meNCoTA/P3f7jk2dO3UtKS0GAPTs2Y9Op2/aslYqlZaXl63/eYWZ2YcUx43sqo+Li1tlZcX9+7frIlGEiIhRt+/cPHcuXiAUJD9/snP31q5dejQepDaiU0dmTp9/587NK39fUKlUaWnPf1zzXdzi2XK5HACw5/df6XRG9OiJlpZW06bNO3zk9/fFRchZFhaW23dsEggFtfzaI0f3Ojm5+Pp2MOOaTY6deejwnvT0FKlUeuv2jW8WzarrBvnUl1BaWqK7WmNFP651dHBatnRtekZKeGTwDyvipk//KiwsKiMjdfqM8Vwu96e1W6USSVhEvylTR0ePnuji4ob0+zSyqz7du/Xu4Bfww4q4xKSE+tuHDomY+uWc+FNHIiJDNm5cHRgQtGzZTy3WqeMn9fcP3LPrWFra8y+iBnz73TyJWLx2zRY6nZ6ennL+z1OL45Yjd10R4SOdnV03/G8VcpaXZ2sXF/fR0UNGfBFaUV625sdNSNg9bmzsorjlJ+IPhUcG/7Z9o5trq0Vxy7XWW/clPEv+R0epRoz27HT//F2lUICO/azxkGRsrFz1rVAo2LxpF/ZVn9+eHznTyYJHw75qVDHQcQgQSCMY6DgEHBkRNUCl1J5laOn3a3r06IO5IkhDoGsbsmvnkU/tsrJsScj04yrtN1iQFgNd2xBHBye8JUCaAMa1EOIBXQshHtC1EOIBXQshHtC1EOIBXQshHtC1EOIBXQshHtC1EOKh3bVMDhkugWME0BlkOssIGybtH8nGkVH2TqJ1F4QoiGqVUrGKxTHC+b3aXevizZJL1Ea5wJrp8DaV36GnSa3+TALDvnS892epVKTCWhFEH2T+UyusVnQeYIW3EFTQPpcBgV+lPLX1nbsP14JHZ3KMMDwyPihUclWxTKlQy8TKIbEOeMtBi8Zci5D5RFBeJMMmWsjKynJwcDAzM8OgroL8AksrS3NzLfMrP5+0tDQyiUyn01lsFofDYbFY2My8ZZlRWFyKnQuzla8xrzfftGuxQSKRvH37trq6uk8fjCYLLF68ePjw4cHBwWgUvmHDhvj4eDKZrNFo2Gy2paUlk8l0cnLatm0bGtWZGgbh2jVr1syZM8fGxgbLSsvKyrhcLpuNSpuUm5s7d+7csrKyui0ajUaj0djZ2V29ehWNGk0K/KPVI0eOdOzYEWPLAgDs7OxQsiwAwMPDw8/PT61W120hkUiOjo7QsnoBT9cePXoUABAdHR0REYF97Rs3bnz8+DF65U+YMMHW1rbuLZPJvHz5MnrVmRS4uXbZsmVIDjYkYxf2lJWVicVi9Mrv2LGjp6cnEoCRSKSgoKCUFLjog37AIa59/Phx165d379/7+SE57xCVONahKSkpDVr1tTU1CQnJwMAnj171rlzZ/SqMx0wbWs1Gs20adMkEgkAAF/Loh3XIoSEhLi6ujo7OyNvEcuOHj1a9t9MkpDmgl1bW1payuVys7OzO3bsiE2NjbNhw4bg4OBu3bphXG9paemJEycWLlyIcb3GBEZt7eLFi2trazkcjoFYFgBQUVEhkeAwQsje3h6x7F9//YV97cYB6m2tRqO5ceMGlUoNCQlBtaLmUlFRgTy1wkvAwYMHqVRqTEwMXgKIC7quXb9+/ZIlS0gkktZ88xDk/kyhUCDrjkB0BMUIYcuWLW3btiWTyYZp2Q0bNvzzD865YJH7s4ULF2ZnZ+OrhFig4tpLly4BAGbMmBEVFYVG+XoBr7j2Y7Zv3448cIHoiP4jhDlz5oSHhw8dOlS/xeod3OPaj7lw4UJkZCTeKgiAPtvazMxMAMCiRYsM37IAAB6PZ1CWBQC4uLjMnj0bbxUEQD+uVavVs2bNEolEAABPT0+9lIk2hhDXNqBz585xcXEAgPLycry1GDR6yF8rFApLSkqmTZtGrMeVhhPX1sfb2xsAkJiYyGKxcBlURAw0n8f3339fUlLymYXgQnl5uVgsxlvFJ1m9erVSqcRbhYHyWXdjx44ds7OzGzRokA7HQpqNSqW6fft2//798RZicLQwrt29ezcAYNy4ccS17Lp16x49eoS3isagUCj+/v69evVSfmJ1E5OlJa5dunQpMmKL0CvAV1dXS6VSvFU0AY/HS0xMrKysLC0txVuLAdG8COHevXu9e/eurKzEfsKM3qmurmaxWHiNSW8ur169SkhIWLBgAd5CDIJmtLWxsbEqlQoAYASWBQBYWVkRxbIAAB8fH2tr6zdv3uAtxCDQta2Vy+VZWVnt27dHXxJGLFu2LDw8vHv37ngLaQYCgaC4uNjDw8PER9s03dbKZLKFCxfS6XRjsiwAYPbs2UVFRXiraB5mZma5ubk///wz3kJwpumnDGq1+unTp5iIwRQXFxeVSkXEUYJhYWF4S8CZpiMEtVqdnJwcFBSElSRM0Wg0U6ZMOXToEN5CIM3AIHLP4EtGRkZpaWloaCjeQnTi+PHjEyZMwFsFzuga12IiBh/8/PyCgoIIEeNmZmb+/fffeKvAn6Zda6xxbX0sLCzs7e0Nf4ClSqWaMWMG3irwx9Tj2vqUl5fn5eV16dIFbyGQJoBx7X9QKpXJycldu3bFW4h2Tp06FRISUj99mGkC49r/QKVSg4KCunTpYpg/5o0bN0LLwrhWC2Qy+cmTJwUFBXK5HG8t/6G6unrdunV4qzAIYFz7SS5dutS1a1c7Ozu8hUAaAuPaxhg2bNjly5cNJJ/DlStXHBwcOnXqhLcQ/NEprp0/fz4mYgyOK1euKJXKiooKvIUA5PkCkvEXolNc+/z5c0zEGCI0Gu3mzZvIpHkc0Wg0kydPbtu2Lb4yDASd4trU1NTAwECsJBkiX3/99S+//IK3CsgHYFzbDN68edOmTRtcqr5//35JScnIkSNxqd3QgHFtM3j48OGzZ89wqToxMZFwIyrRA8a1zSA2Nvbhw4f1t/Tq1evkyZMYVD1y5MiBAwdiUBEhgHFtS7h9+3a/fv1CQ0Orq6s7dux48OBBvBWZFk23tWQyGVq2AXl5eX369KmtrSWTyaWlpWj3MGRnZ8OnYvWBcW1LOHbsWF2OsLKyssTERFSre/bsGQxq6wPj2mYzdOjQ6urqurcajSYpKQnVGkNCQmbNmoVqFcSiadcyGIwdO3ZgIoYATJgwQSAQNFggt7q6GlkHDyXs7OzMzMzQK59wUFatWtX4ESQSyd7eHis9hs7IkSN9fX05HI5cLieTyWKxWK1WS6VSJpPZu3dvNGpUKBTR0dFjxoxBo3CC0vTMcplMFhcXt337dkz0fEAh05QXyfiVCqVCrcPhmMIFPmF9fcL6gqKiotzc3NzcXKFQ+Pa5PONBLRrVFRYWevL6oVS4ocE2o/KcGOY2Tdiy6Z4viUQyaNCgu3fv6lVeY7x4xM9KFirkaodWbKlIhVm9ENwRi5SiGqW1PW1IrEMjh+nUX5uRkeHv769vhdrJfCp8kywIGeOITXUQAyQ3Q5idUhs11/lTBxjWOIS8l+LkpJqBE3FeGBqCOwWvRLkZ/LBp2hsvnfpr582bh4IwLaTerukyiIdNXRBDxs2Ho1KB0nztCYZ16q9NTU1FQZgWCrPFFjw6NnVBDBwmh1JRrH3qngH114r5KgsenYTRKuoQQ4drSRUJtKf212kcAka3YiQgk8AeA8gH1CoAPtHtqVNcCxcchBgUOsW1GRkZmIiBQHRCp7gWWacJAjEQdIprjSy3PYTowLgWQjxgXAshHjCuhRAPGNdCiAeMayHEA8a1EOIB41oI8TD1uPbsufgBg7p9vP30meODhvRo8vQRUQOOHN2n+/G6oMeijBWd4trp06djIgZncnKyx47/sNinr0+HiROm6n5uc49vwLnzf6zfsFIvRRkmI6IGvC/W24puOq2ji3v2Vmx4lflv+N6+vX/79s0Y6dbc4xuQ+fpFXUbyzyzKACl6X1hbW6PHAnWKa/fu3avHKvXI2bMnR44e/CYrc8y44QMHd586fezLVxn37t8KjwweFtbnx9Xf1fJrAQAvXqSFhAa9ynxRd+LY8WF7ft9Wv6h9+3ds2ry2tLQkJDTo7Ln4+pfpocN7n4w//MOKuJDQoLCIfsuWfyMUChsoqX+8SqU6cfLQkGG9hg7vvWjxnBcv0pDtublvf922YdLkkUOG9Zo5a+Kly+eR7V8tmHr9+pWEhMshoUE5OdkNIoQjR/dNjBkxaEiPmNioX379GUnFkJ39BvlEiKox44bv3vOrLpOp0tNTFi2eEx4RHDtl1K7dvyAZdORyeUxs1IqVi+sOi1s0e/acSWq1+mT84RFRA+7eS/pi5MD+A7pMnPTFjZtXGy8NALB8xaI1a5fu3vNrSGjQocO/T4wZAQCYMDFy5apvdf7fNoZOcW27du30UpneodHpAgH/yNG9mzftvnA+USqVrv95RULC5QP7Th05dO5Z8uNz53RNeDht6tyxYybZ2zsk3Xw6Mmrsf2qh0c+cPRH1xdib1x9vWP9bXu7bHTs3N1LUnt+3Xbx4ds3qzcu+X2vDs13y/VeFhQUAgN+2b3z67J+vF3y3ft2vQ4dGbt7y05OnjwAAv/2638fHb9Cg4Uk3n3p6etcv6uCh3X9eODVn9jdnTl+bHDvz+o0r58//AQCg0+kAgE2b1wwcMCzh6sPvlvz4x6mjt27faPwzFhTkffvdPIVSsXPH4ZXLf87Kyvxm0Sy1Wk2n07/7dtXde0lPn/0DALh1+0Za+vNly34ik8kMOkMkEt66df3k8Yvnz14P7jdg3frlRe8LGykNSbD++vXL3Ly369Zu/WJE9PqffgEAHD924cdV/9Px39E4xI5ryWSyQqGYPGmmi7Mrm83u1q1XcXHRNwuX2tra8Xi2HToEvM3J+vxaSCSSl2frToFdyGRy+/b+YWFRiUnXVCrtA9hraqpPnzk+dmxsl6DuvXsHL45bHhjQpbKyAgCwcuWGjRt2dArsEhgQNCJydGvvto8fP2ikXoFQcDL+cOykGT179jU3Mw/tP3hEZPTR4/vVajWZTAYABPcb2K9vKI1GCwwIsrd3ePPmVeMf5MbNv2lU2upVG11d3T09vePifsjMfPHg4R0kLIkIH7l16zqxWLxr99bp0+a5OLsCADQAKJXKqC/GMplMCwvLKZNnsVisW7euN14ahUKpqCxfvWpjjx59LCwsP+/r14JO/bUUCkXvFesRL6/WyAs2i21jw7O0tKp7KxQK9FTFvynCnZ1d5XJ5aVmJ1iNzcrMBAD4+fshbKpW6ZvWmjh07AQA0avXps8djYqNCQoNCQoOysl/X1FQ1Uum7d/kKhcLXt0Pdltat29XW1hSXvEfetmnjU7eLyzVr8sNmZKS2a9e+zkbOTi4O9o6pqR9yPc2YPl8ml82aE2Nv7zh61H+WRff2/rAeBIVCcXR0LniX12Rp7m4eDAajcT0tpum7MQaD8fXXX6NUvV6ov7ISSqssMRjMBq9FooahLQJiHTaL3WC7SqVa8t1XGo1m5oz5gQFdOBzOnHmTG6+0qqoCAMCsVzWLxQYASMRiJpOJXGqa9SmEQkFW9uuQ0P8sHVddXYm84HA4IyKmUvYGAAAQEklEQVSj9x/YOWRweIOvsb7/GAymWCRqsjQ6apbVybWGHNe2mE9d3z9FfY/KZFIAAIvJ0nokh8NFLu4Ntr9+/fJNVubmTbs6BX5YXbrJphEpSiKV1G2RSMQAAB7PtmXXEGsbXgcWa8rk/6RntDD/0FjW1tac//OPkOCBR4/tC+0/xN7+3+wvIpGobtEomUyK/GYaLw1ViB3X6giNTgcASP//388X8KuqKptVQmrqv8sxZGe/ZjKZDg7aU420bt2OQqHUHa9Wq79dMu/69StI1w/P5sMquDk52e/e5TdeqZdXGwqFkpHx77T+V68yrKys60Kg5uLl2bqivCygY+fAgCDkz8rS2s2tFbJ322//c3fzWLF8vZdXm02b19Q/8XnKE+SFWCwuLCxo1cqrydJQRae4luj9ta3cPc24ZtcSLiGrkv+8YaWZmfnHh7m4uFVWVty/fxu55a9PeUXZmbMnVCpVfn7upcvng/sNpFK1X6bMzcwHDRx+4cLpv6/+9Tzl6bbf/vc85amPb4dWHl4kEun0meNCoTA/P3f7jk2dO3UtKS1GznJ2dn39+uXzlKc1NdX1iwoNHXL02L4HD+4IhIKr1y7+dfHMqJHjW/w9REfHKFXK7Ts3S6XSgoK83Xt+/XLamPz8XADAnbuJd+8lxcX9AAD4dtGK5OdPrt/4GzmLSqWeOxdfWFigUqkOHNwll8uDgwc2XloDXN1aAQBu375Rv/Pxc9Cpv5bo6w7Q6fTly9dnZKSGhAaNnxgxIHSog73jx72b3bv17uAX8MOKuMSkhAa7wsOi0tKeDxjUbfKXo7292sydE9dIdQvmLwkICNq85adv4ma9fJm+ZvVmF2dXRwenZUvXpmekhEcG/7Aibvr0r8LCojIyUqfPGA8ACB8epdFoFi2ek5v3tn5RX81d3LNH3zU/LY0aOTD+jyMxE6eNiY5p8fdgYW6xf98fTAZz2oxxsVNGpaYlL1m80surdW1tzabNa8ePm+Ls5AIAcHNrFfXF2O07NtXFOSOjxi1YOH3AoG5Xr/219Ps1yGGfKu3jep2dXIYMDj9wcNf+/fpJrGFAeb7EAtXJjQXRcR54C2lI5BehI6PGTYqZhrcQHDh7Ln7nri03rz/GvuqUW1UMJug62PrjXTrFtV9++SU6wiCQlqDTOISsLD301UMw4I9TR48d2691l4en97Zf9mGuCBV0yl+bk5Pj7e3d+GGfj8FGCARCIBR8qlOMRqXxeLaYK2o5jUQIOvXXYmBZiF4w45qZcY1/3REY10KIh079tTCuhRgUJtFfCzEydBpfC+NaiEHRtGulUmlsbCwmYiAQnWjatRqNJicnBxMxEIhONO1aJpN55MgRTMRAIDrRtGtJJJKHB+z5hxgQMK6FEA8DimtpDDKLa9AT1CAYw+Jo94MBxbU0Okml1PArFRjUBTF8ygokVg7al0w0rLjWt5tF/ksRNnVBDBmxQKWUq529tE/OM6y4tnOopaBalvmYj011EMNEIVPfPVcyJNbhUxOumx7zhXF/7eAY+ysHiyUCBY1JtnFkqpSfWN4PYoxIhCp+pfz1M/64Ra7mNrRPHdb0+FqNRpOXl4dx59fbNFFpvlQqUYlqTW6NUpFIVFtb6+SkfQ6wccM2o9i5MDr0tmj8MAOaNwZBuHfv3tmzZ7du3Yq3EMOladdKpdLp06cfPXoUK0mmjlAorK6udnV1xVuI4aJTXJuXl4eJGAgAAHC5XC6Xi7cKg0an/tpjx45hIgYCAAApKSlbtmzBW4VBo1N/rbu7OyZiIACJEN69e4e3CoMGxrUGh1AorK2tdXZ2xluI4QLjWoMDxrVNAuNagyMlJWXTpk14qzBoYFxrcAiFwqIivS1yZJTAuNbggHFtk8C41uCAcW2T6BTXnjyp6/pHkM8HxrVNolNc6+LigokYCIBxrS7oFNdOmTIFNreYAePaJtEpri0sLMREDATAuFYXYFxrcCQnJ2/YsAFvFQYNjGsNDrFYXFKifeFICAKMaw0OsVjM5/MdHBx0ONZEgXGtwcFms9nshguaQuoD41qDA8a1TQLjWoMDxrVNolNcO2nSpFOnTmElydSBcW2T6BTXFhcXYyIGAmBcqws6xbWnT5/GRAwEIHHtqlWr8FZh0OgU1zo4OBw+fBgTPRBw+/btMWPG4K3CoGnatQitW7ceO3YsymJMnatXrwIAJk2a5OPjg7cWg0ZX1/bs2XPv3r0AgCdPnqAsyUSZM2eOQqEAANjY2OCtxdDR1bUAADMzM+ReISIiQiaToanKtHj9+jUAYOHCheHh4XhrIQYtyfP1/v17hUJhZmZmba1lZV6I7qhUqrlz506fPr1z5854ayESLc9OV11dPXv27N9//93c3FzfqkwCkUiUn58vFouDgoLw1kIwPiun4tu3b58/fz5q1Ci9SjJ+NBrNokWLli1bBi9WLaMZce3HeHl5IZb9/vvvhUKh/lQZOXv27ImIiICWbTH6yV/74sWLPXv2bNu2TR+SjJlt27bNnz8fbxWE57Pa2jrat2+PWPbMmTOwe+FTTJkyJTAwEG8VxoCec4Xn5OTExMQkJSXR6drX3DFNbt26FRwcLJfL4deiF/TT1tbh6el5//59pVKZlZWl35IJikKhGDp0qJWVFQAAWlZfoLUuQ0VFRURExJ9//mlnZ4dG+YSgqKiIzWYrlUpbW1u8tRgVem5r6+DxeLdu3TLZVEtCoXDUqFEUCsXKygpaVu9gsQbOkCFD9uzZY1KJGRMTE728vEzqI2MJWm1tfeLj469du4ZBRbgjEAhmzZoFAOjfvz+0LHpgut7Y+vXrx44di/GCe1iyevXqUaNG+fr64i3E2NFgSGVlZWxs7Mfbo6KisJShd0Qi0f79+/FWYUJgESHUYW1tfejQIaT/sv5ctKysrCVLlmCppMUIhcLIyMj+/fvX3xgWFtavXz/8RJkcmLq2jsDAwBkzZpSWlgIA+vTpQ6fTU1NTU1JScBHTLPbt21dSUsLn8yMiIgAAz549q7v3wluaCYGPay0sLC5evKhQKCIiIiQSCQCgrKxs586duIjRndzc3KSkJJVKhfTFdunSBWaKwAV8XIvg4uJSl4uJTCZnZWUlJibiqKdJ9uzZU7d+HYlEYjKZ9vb2eIsyRfB0bd++fcnkfwXU1tYiU9MMk+Tk5PT09PqCJRIJnDODC7i5dsiQIQKBAACgVqs/SCGTi4qKDDan2N69e+sSGanVarVardFoCgoK8NZlijSdewYlrl69unbt2uLi4qqqqpqaWirgktUssoZ18/yrAG8+Xqo+RXJycm0R243XSUORqYGYwlDxeDwej+fp6Ym3NFME06cMDZCK1bkZwrdpoppKpUSgoDBIZCoAZA2bxcFLUiPIlGKVlKSSazQqQCaTPP05Xn4c17YwtREO4ONajQbcu1BRnCfXkMgsS465LRuQsFfRchRSJb9MLKkVk4E6aIBlm05meCsyLXBwbdq92jvnyp3aWlu7WWBctd5RylTluZUqqWLYFAdrBzh8FiOwdu3fh0tkCrqlM+H9Wh+pQF72tqLbIMu2nWGjiwWYuvb4zwVmDhbm9sa5LFHJ6zL/HhzfbjA7BOpg59pTvxSxbSy4PBY21eFCyety7w7MoFBLvIUYORj1114+UMK2NjNuywIAHNraZqWI36bD1BDogoVrk5NqlBo619YQ+7P0jqOv/bOb/NoKBd5CjBnUXSsVqx8nVFk4GdXtV+OweeY3TpbhrcKYQd21d89XOHibVmogrg1LLNIUZknwFmK0oOvamnJFVZnS0snk+oNsvXjJt2rxVmG0oOvaN88FZANOXZGcdm3R8m5isf6HPTC5tPJCKYxuUQJd12anirg2Jvqk3syWk5MBOxNQAUXXivkqhVzDsmCgV4Uhw7XhFLyGifpQAcWRipUlcjKVgl75Ofkp15P2vSt6ZW7G82nTa1D/6Qw6CwBw92F84p0js6bsOHzyu7KKPEd77769xncJHI6cdenqb09TrzDo7ED/wTxrFOfPMDi0d+li9Mo3ZVBsa0V8JYWGlmtLy/P2HV6gUirnzzgQE/1T0fvMPQfnIgPMqRS6WMI/d2njmKjlG1c/au/T7/SfP9XyywEADx6fffD4TNTwxQtmHrSydLhx+wBK8gAAFBpZKVOrVejVYLqgGiEo0Wtrn6deo1BoseN+trN1d3TwHhW5tKDwxcvXdwEAJDJZpVIMDp3h7upHIpGCAoap1aqi4jcAgHsPT/m3D/X3689mm3frHOHVqhNK8hAYbKqIr0S1CtMERdeqVCQqDa0IJK8g1dXFl8P58MSfZ+NiZemYk/e87gA35/bICzbLHAAglQk1Gk1F1Tt7u38z37g4o7sYHcucppDjNujeiEExrmVxSArU8oZLpMKi4teLlnerv1EgqKx7TSI1HGculYnUahWT+e+IMzqNiZK8D3oqZFwLFCN7kwVF13LMqSoFWmGdmZmNBz1gcP8Z/6mR3dhzYyaDQyZTlMp/f0gyOYp3S2qVRq3W0Jl4zoI2VlB0LdeSRmeg1dI4ObROSb/u5dGprk0tKcuxtXFr5BQSiWRl6ZhXkN6nx4cFgV+9uY+SPACASq5y9DDRvmq0QbElsHWh15SKlXJUmtt+vSaoVMoLV7bK5dLS8rxLV3/bvH18aXlu42d19BuQmnEjLSMRAHDz9qF3Ra/Q0IbALxdb2NLQK9+UQff61cqXwy9H5SrMYVssmneCTmNu2Tlx47YxOfnPo79Y7uTQuvGzBvSb0iUw7NzljYuWd3vz9p+wQV8BADQAlRsmUZWoTYBJDM7EHnTnMuS9FP9zQ2jf2uQW4daowfuM4gnfuhBr7jFRQLutZcuEUqnQ5AaRlOdWtw4g2HR5AoF67pl+X/Du/FXp6u+gdW9V9fstO2O07iKTKGqN9pi4Z9eRwwbO0aPIlesHq9RaHgeoVEoAAIWi5VsK8Bs4KvI7raWplZrKd7XR82BuULTAYrbjpf0lZI45W9swGrVaLZOJtJ4ll0vpdO39qRQK7VO7WoZEIvjULpVKqdW1jWioyq9p25HWvgecrIsWGM3R3R6X7RfqYQpXzNoSIUUtCZuq/doC0QsY9YGPX+yW87gQm7pwRFwj4xfXQsuiDXb5EATVylO/Fnl1M9rk2sIqqbC0Zuw3zngLMX6we95oZkUNn+rw8mauXGKEw6Bq3gukldCyGIF1ni+VUnP5QIlUSrbxsKZQjeEZvahKWpFX5eXH7h1pct3SeIFPJtAXD/n3LlTYelgyzZlsS0JO0dGoNfwysbhaRKOq+47g2bkR8lMQFDyzLqfd5b98zK8pl1u7mAMSicagUBlUCpVkmCNSSQAo5SqFTKWSq6UCqbBK6taW07GPhWtbI08DZYDg6VoEqVhdkCmueC8T1qhEfKVSoVGrDdG3XEuaWqnmWFAtbKh2LgyYJRxH8HctBNJcjOF+CGJqQNdCiAd0LYR4QNdCiAd0LYR4QNdCiAd0LYR4/B+Cc/GNZ5GnaAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "app=graph.compile()\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "61383fe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61383fe4",
        "outputId": "2b99bd5b-2f0c-4172-a627-282cbf2f7bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************addition expert called\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"what's ((3 + 5) * 12)+2. Provide me the output\", additional_kwargs={}, response_metadata={}, id='d7c4a645-230e-4429-9cce-4739bac97d22'),\n",
              "  AIMessage(content='The result of the expression ((3 + 5) * 12) + 2 is 98.\\n\\nStep-by-Step Explanation:\\n\\n1. Solve the parentheses first: 3 + 5 = 8.\\n2. Multiply the result by 12: 8 * 12 = 96.\\n3. Add 2 to the product: 96 + 2 = 98.\\n\\nFinal Answer: 98', additional_kwargs={'reasoning_content': \"Okay, so I have this math problem to solve: ((3 + 5) * 12) + 2. Hmm, let me break it down step by step. First, I remember that in math problems, I should follow the order of operations, which is parentheses first, then multiplication and division, and finally addition and subtraction. So, looking at the problem, the innermost part is the parentheses: (3 + 5). That seems straightforward. 3 plus 5 is 8. \\n\\nNow, after solving the parentheses, the problem becomes (8 * 12) + 2. Next up is the multiplication part. So, 8 multiplied by 12. Let me do that calculation. 8 times 12... I can think of 8 times 10 is 80, and 8 times 2 is 16, so adding those together gives me 96. So now the problem simplifies to 96 + 2.\\n\\nFinally, I just need to add 96 and 2 together. That's easy, it equals 98. So the final result should be 98. I think that's correct, but let me double-check to make sure I didn't make any mistakes. Starting over, (3 + 5) is 8, multiplied by 12 gives 96, and adding 2 gives 98. Yep, that seems right. I guess the answer is 98.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 383, 'prompt_tokens': 162, 'total_tokens': 545, 'completion_time': 1.392727273, 'prompt_time': 0.010263873, 'queue_time': 0.202266487, 'total_time': 1.402991146}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--312ed302-5070-4057-ba73-9a04814e5177-0', usage_metadata={'input_tokens': 162, 'output_tokens': 383, 'total_tokens': 545})]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "app.invoke({\"messages\":[(\"user\",\"what's ((3 + 5) * 12)+2. Provide me the output\")]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "5a004e5c",
      "metadata": {
        "id": "5a004e5c"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing import Literal\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import MessagesState, END,StateGraph, START\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "49341bca",
      "metadata": {
        "id": "49341bca"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e30ebd74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e30ebd74",
        "outputId": "331a73bb-b464-4bd1-f3b4-7d321212ee0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "04b255fe",
      "metadata": {
        "id": "04b255fe"
      },
      "outputs": [],
      "source": [
        "TAVILY_API_KEY=\"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\"\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"]=TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "18771717",
      "metadata": {
        "id": "18771717"
      },
      "outputs": [],
      "source": [
        "tavaily_tool=TavilySearchResults()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "2f886735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f886735",
        "outputId": "9556ba86-bacc-4da9-c61e-7237bb333e31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Gross domestic product - Wikipedia',\n",
              "  'url': 'https://en.wikipedia.org/wiki/Gross_domestic_product',\n",
              "  'content': 'Gross domestic product (GDP) is a monetarymeasure of the total market value( of all the final goods and services produced and rendered in a specific time period by a country( or countries.( GDP is often used to measure the economic performance of a country or region.( Several national and international economic organizations maintain definitions of GDP, such as the OECD and the International Monetary Fund.( [...] GDP (Y) is the sum of consumption (C), investment (I), government expenditures (G) and net exports (X âˆ’ M).\\n\\nY = C + I + G + (X âˆ’ M)\\nHere is a description of each GDP component: [...] Sustainability of growth â€“ GDP is a measurement of economic historic activity and is not necessarily a projection.\\n   Income distribution â€“ GDP does not account for variances in incomes of various demographic groups. See income inequality metrics for discussion of a variety of inequality-based economic measures.(',\n",
              "  'score': 0.8665964},\n",
              " {'title': 'Beginners:GDP - What is gross domestic product (GDP)?',\n",
              "  'url': 'https://ec.europa.eu/eurostat/statistics-explained/index.php/Beginners:GDP_-_What_is_gross_domestic_product_(GDP)%3F',\n",
              "  'content': 'GDP \"Glossary:Gross domestic product (GDP)\") is the most common measure for the size of an economy. It measures the total value of goods and services produced by that economy during a specific time period, typically a year or a quarter. This helps us understand changes in the size of an economy across different time periods and serves as a broad indicator for the standard of living of its population. [...] GDP is a key measure within a wider framework of economic statistics which is often simply referred to as national accounts. The European system of national and regional accounts (ESA) defines the binding standards and methods used for compiling these accounts, whereas the global standard set by the United Nations (UN) is called the System of National Accounts (SNA) \"Glossary:System of national accounts (SNA)\").\\n\\nGDP can be calculated in 3 ways, but the most common is the production method. [...] GDP is essential for anyone involved in economic decision-making, whether at national, international, or individual level. It provides a snapshot of a country\\'s economic performance and future prospects.\\n\\nThe change in inflation-adjusted (so called real) GDP over time is used as the main economic indicator of economic growth in a country.\\n\\nGovernments use GDP data to design economic policies:',\n",
              "  'score': 0.8591094},\n",
              " {'title': 'Gross Domestic Product (GDP) Formula and How to Use It',\n",
              "  'url': 'https://www.investopedia.com/terms/g/gdp.asp',\n",
              "  'content': 'Gross domestic product is a measurement that seeks to capture a countryâ€™s economic output. Countries with larger GDPs will have a greater amount of goods and services generated within them, and will generally have a higher standard of living. For this reason, many citizens and political leaders see GDP growth as an important measure of national success, often referring to GDP growth and economic growth interchangeably. Due to various limitations, however, many economists have argued that GDP [...] A countryâ€™s GDP represents the final market value of all the products and services that a country produces in a single year. Another way to measure GDP is as the sum of four factors: consumer spending, government spending, net exports, and total investment. [...] Gross Domestic Product (GDP) includes consumer spending, government spending, net exports, and total investments. It functions as a comprehensive scorecard of a countryâ€™s economic health. GDP may be adjusted for inflation and population to provide deeper insights. Real GDP accounts for inflation, while Nominal GDP does not.\\n\\n### Key Takeaways',\n",
              "  'score': 0.8184036},\n",
              " {'title': 'What Is GDP & Why Is It Important? - Harvard Business School Online',\n",
              "  'url': 'https://online.hbs.edu/blog/post/why-is-gdp-important',\n",
              "  'content': 'GDP stands for gross domestic product, which represents the total monetary value, or market value, of finished goods and services produced within a country during a period, typically one year or quarter. In this sense, itâ€™s a measurement of domestic production and can be used to measure a countryâ€™s economic health.\\n\\n### Nominal GDP vs. Real GDP\\n\\nGDP is typically spoken of in two main forms, depending on how itâ€™s calculated: nominal GDP and real GDP. [...] Image 9: View Video\\n\\nGDP Equation\\n------------\\n\\nGDP can be expressed as an equation that sums up all of its components: a nationâ€™s level of consumption, investment, government spending on goods and services, and the difference in profit between exports and imports.\\n\\nGDP = Consumption + Investment + Government Spending on Goods and Services + (Exports â€“ Imports), which looks like this: Y = C + I + G + (X-M)\\n\\nComponents of GDP\\n-----------------\\n\\n### 1. Consumption (C)',\n",
              "  'score': 0.8058924},\n",
              " {'title': 'Domestic Product (GDP) growth - Glossary | DataBank',\n",
              "  'url': 'https://databank.worldbank.org/metadataglossary/world-development-indicators/series/NY.GDP.MKTP.KD.ZG',\n",
              "  'content': 'Code NY.GDP.MKTP.KD.ZG\\nIndicator Name GDP (annual % growth)\\nLong definition Gross domestic product is the total income earned through the production of goods and services in an economic territory during an accounting period. It can be measured in three different ways: using either the expenditure approach, the income approach, or the production approach. This indicator denotes the percentage change over each previous year of the constant price (base year 2015) series in United States dollars. [...] goods and services. These may be used for consumption in the period to which the accounts relate or may be accumulated for use in a later period. In simple terms, the amount of value added generated by production represents GDP. The income corresponding to GDP is distributed to the various agents or groups of agents as income and it is the process of distributing and redistributing income that allows one agent to consume the goods and services produced by another agent or to acquire goods and',\n",
              "  'score': 0.8016413}]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "tavaily_tool.invoke(\"what is a gdp?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "65cb6923",
      "metadata": {
        "id": "65cb6923"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "\n",
        "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
        "    return result_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "27a2595a",
      "metadata": {
        "id": "27a2595a"
      },
      "outputs": [],
      "source": [
        "code = \"\"\"\n",
        "x = 5\n",
        "y = x * 2\n",
        "print(y)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "14226e35",
      "metadata": {
        "id": "14226e35"
      },
      "outputs": [],
      "source": [
        "repl=PythonREPL()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "0e33a289",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0e33a289",
        "outputId": "4a738d79-afe2-4331-821c-650a79f12e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "repl.run(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "c514ecaa",
      "metadata": {
        "id": "c514ecaa"
      },
      "outputs": [],
      "source": [
        "members=[\"researcher\",\"coder\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "fb63d7d6",
      "metadata": {
        "id": "fb63d7d6"
      },
      "outputs": [],
      "source": [
        "options=members+[\"FINISH\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c8d457fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8d457fc",
        "outputId": "5ebbb08b-3648-4d76-fcff-53d9f839b5b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['researcher', 'coder', 'FINISH']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "f45001a9",
      "metadata": {
        "id": "f45001a9"
      },
      "outputs": [],
      "source": [
        "class Router(TypedDict):\n",
        "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
        "    next: Literal['researcher', 'coder', 'FINISH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "8abcae0f",
      "metadata": {
        "id": "8abcae0f"
      },
      "outputs": [],
      "source": [
        "class State(MessagesState):\n",
        "    next:str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "4315e5e1",
      "metadata": {
        "id": "4315e5e1"
      },
      "outputs": [],
      "source": [
        "system_prompt=f\"\"\"\n",
        "You are a supervisor, tasked with managing a conversation between the following workers: {members}.\n",
        "Given the following user request, respond with the worker to act next.\n",
        "Each worker will perform a task and respond with their results and status.\n",
        "When finished, respond with FINISH.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "30f9e656",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30f9e656",
        "outputId": "1a5493d2-2b81-40bd-bf29-bff40bd60903"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"\\nYou are a supervisor, tasked with managing a conversation between the following workers: ['researcher', 'coder']. \\nGiven the following user request, respond with the worker to act next. \\nEach worker will perform a task and respond with their results and status. \\nWhen finished, respond with FINISH.\\n\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "[{\"role\": \"system\", \"content\": system_prompt},]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "04b10d87",
      "metadata": {
        "id": "04b10d87"
      },
      "outputs": [],
      "source": [
        "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt},] + state[\"messages\"]\n",
        "\n",
        "    response = groq_model.with_structured_output(Router).invoke(messages)\n",
        "\n",
        "    goto = response[\"next\"]\n",
        "\n",
        "    print(\"below my goto**********************************\")\n",
        "\n",
        "    print(goto)\n",
        "\n",
        "    if goto == \"FINISH\":\n",
        "        goto = END\n",
        "\n",
        "    return Command(goto=goto, update={\"next\": goto})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "997fe56a",
      "metadata": {
        "id": "997fe56a"
      },
      "outputs": [],
      "source": [
        "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "\n",
        "    research_agent = create_react_agent(groq_model, tools=[tavaily_tool], prompt=\"You are a researcher. DO NOT do any math.\")\n",
        "\n",
        "    result = research_agent.invoke(state)\n",
        "\n",
        "    return Command(\n",
        "        update={\n",
        "            \"messages\": [\n",
        "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
        "            ]\n",
        "        },\n",
        "        goto=\"supervisor\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "93ce7b46",
      "metadata": {
        "id": "93ce7b46"
      },
      "outputs": [],
      "source": [
        "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "\n",
        "    code_agent = create_react_agent(groq_model, tools=[python_repl_tool])\n",
        "\n",
        "    result = code_agent.invoke(state)\n",
        "\n",
        "    return Command(\n",
        "        update={\n",
        "            \"messages\": [\n",
        "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
        "            ]\n",
        "        },\n",
        "        goto=\"supervisor\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state.clear"
      ],
      "metadata": {
        "id": "gxamKRxrUlFp",
        "outputId": "a5b11249-9957-43ea-b4bf-51e79d5d43f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gxamKRxrUlFp",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function dict.clear>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "bc75a09c",
      "metadata": {
        "id": "bc75a09c"
      },
      "outputs": [],
      "source": [
        "graph=StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "0df6717f",
      "metadata": {
        "id": "0df6717f"
      },
      "outputs": [],
      "source": [
        "graph.add_node(\"supervisor\",supervisor_node)\n",
        "graph.add_node(\"researcher\", research_node)\n",
        "graph.add_node(\"coder\", code_node)\n",
        "\n",
        "graph.add_edge(START,\"supervisor\")\n",
        "app=graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "42dc4911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "42dc4911",
        "outputId": "97e21b1d-6dcb-486a-acc8-7a62dde48ad6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "5aa4f881",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "5aa4f881",
        "outputId": "c2d64d89-86e4-459e-db73-3b6c29858608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "below my goto**********************************\n",
            "coder\n",
            "((), {'supervisor': {'next': 'coder'}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'agent': {'messages': [AIMessage(content=\"To calculate 2 multiplied by 5, I'll use the Python REPL tool to execute the code and get the result.\\n\\n\", additional_kwargs={'reasoning_content': 'Alright, the user is asking \"What\\'s the 2*5? use appropriate tool.\" So, they want me to calculate 2 multiplied by 5. I remember I have access to a Python REPL tool, which can execute Python code. \\n\\nFirst, I need to figure out how to use this tool. The function name is \"python_repl_tool\" and it requires a code parameter. So, I should create a JSON object with the function name and the code as arguments.\\n\\nThe calculation is straightforward: 2 * 5. In Python, I can simply print the result using print(2 * 5). This will execute the code and display the output for the user.\\n\\nI should structure the tool call correctly. The JSON should have \"name\" set to \"python_repl_tool\" and \"arguments\" as an object with \"code\" set to \"print(2 * 5)\". \\n\\nI need to make sure the syntax is correct, using proper quotation marks and commas. Also, ensure that the tool call is wrapped within the appropriate XML tags as specified.\\n\\nDouble-checking everything, I think that\\'s all. The user should get the result of 10 when this code runs.\\n', 'tool_calls': [{'id': 'e1yzqh28t', 'function': {'arguments': '{\"code\":\"print(2 * 5)\"}', 'name': 'python_repl_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 182, 'total_tokens': 499, 'completion_time': 1.3132310409999999, 'prompt_time': 0.011830594, 'queue_time': 0.710046723, 'total_time': 1.325061635}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--64fda087-f43d-4977-9517-89a4f830b3c7-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(2 * 5)'}, 'id': 'e1yzqh28t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 317, 'total_tokens': 499})]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'tools': {'messages': [ToolMessage(content='Successfully executed:\\n\\\\`\\\\`\\\\`python\\nprint(2 * 5)\\n\\\\`\\\\`\\\\`\\nStdout: 10\\n', name='python_repl_tool', id='b3b1f778-b955-493e-acda-52906bc7c6c3', tool_call_id='e1yzqh28t')]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, so the user is asking for help with a math problem, specifically \"What\\'s the 2*5?\" They\\'ve also instructed me to use an appropriate tool. I remember from the tools provided that there\\'s a Python REPL tool available. \\n\\nFirst, I need to figure out how to use this tool. The tool requires me to send a JSON object with the function name and the arguments. The function name is \"python_repl_tool\" and the argument is the code I want to execute. \\n\\nSince the user wants to calculate 2 multiplied by 5, I should write a Python print statement that does this calculation. So, the code would be `print(2 * 5)`. \\n\\nI need to format this correctly within the tool call. I\\'ll structure it as a JSON object with \"name\" as \"python_repl_tool\" and \"arguments\" containing \"code\" set to the print statement. \\n\\nI should also make sure to include the unique ID for the tool call, which I\\'ll generate as \"e1yzqh28t\" for this example. \\n\\nPutting it all together, the tool call should look like:\\n{\"id\":\"e1yzqh28t\",\"name\":\"python_repl_tool\",\"arguments\":{\"code\":\"print(2 * 5)\"}} \\n\\nThis should execute the code and provide the result to the user.\\n', 'tool_calls': [{'id': 'e1yzqh28t', 'function': {'arguments': '{\"code\":\"print(2 * 5)\"}', 'name': 'python_repl_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 265, 'total_tokens': 582, 'completion_time': 1.252670042, 'prompt_time': 0.02359267, 'queue_time': 0.202523831, 'total_time': 1.276262712}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4f24133d-10a7-41c7-b040-623229dfb144-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(2 * 5)'}, 'id': 'e1yzqh28t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 265, 'output_tokens': 317, 'total_tokens': 582})]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'tools': {'messages': [ToolMessage(content='Successfully executed:\\n\\\\`\\\\`\\\\`python\\nprint(2 * 5)\\n\\\\`\\\\`\\\\`\\nStdout: 10\\n', name='python_repl_tool', id='a22d3eda-3a4d-4832-aba5-8f509e240d5a', tool_call_id='e1yzqh28t')]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, so the user asked, \"What\\'s the 2*5?\" and specified to use the appropriate tool. I remember that the available tool is the Python REPL tool. I need to call this tool with the correct code.\\n\\nFirst, I should construct the tool call. The function name is \"python_repl_tool\" and the argument is a JSON object with the code. Since the user wants 2 multiplied by 5, the code should be \"print(2 * 5)\".\\n\\nI should format this correctly within the tool_call XML tags. So, it would look like {\"name\":\"python_repl_tool\",\"arguments\":{\"code\":\"print(2 * 5)\"}}.\\n\\nI need to make sure the syntax is correct, especially the quotes and commas. Also, the code should be a string, so it\\'s enclosed in double quotes inside the arguments.\\n\\nOnce the tool is called, it should execute the Python code and print the result. The output should be visible to the user, showing that 2*5 equals 10.\\n\\nI think that\\'s all. The user should get the correct result with this setup.\\n', 'tool_calls': [{'id': 'hw5gfrhf4', 'function': {'arguments': '{\"code\":\"print(2 * 5)\"}', 'name': 'python_repl_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 260, 'prompt_tokens': 348, 'total_tokens': 608, 'completion_time': 1.051604407, 'prompt_time': 0.021811888, 'queue_time': 0.22914744599999998, 'total_time': 1.073416295}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--95456993-fdcc-4caa-95ef-8f1e4f12c0c3-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(2 * 5)'}, 'id': 'hw5gfrhf4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 348, 'output_tokens': 260, 'total_tokens': 608})]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'tools': {'messages': [ToolMessage(content='Successfully executed:\\n\\\\`\\\\`\\\\`python\\nprint(2 * 5)\\n\\\\`\\\\`\\\\`\\nStdout: 10\\n', name='python_repl_tool', id='9ef0d74d-e2d2-4362-a468-9ff57fcfd9e1', tool_call_id='hw5gfrhf4')]}})\n",
            "----\n",
            "(('coder:4ff2e8de-2c86-83c6-a4d7-65fdee66f4e4',), {'agent': {'messages': [AIMessage(content='The result of multiplying 2 by 5 is 10. This can be understood through various methods such as repeated addition, distributive property, real-world examples, and binary multiplication, all consistently leading to the same result.\\n\\n**Answer:** 10', additional_kwargs={'reasoning_content': 'Alright, so I need to figure out what 2 multiplied by 5 is. Hmm, that seems pretty straightforward, but let me think about it step by step to make sure I understand it correctly.\\n\\nFirst off, multiplication is essentially repeated addition. So, when I see 2 * 5, I can think of it as adding 2 together 5 times. Let me write that out:\\n\\n2 + 2 + 2 + 2 + 2.\\n\\nNow, let\\'s add them up one by one:\\n\\n- Start with the first 2.\\n- Add another 2: 2 + 2 = 4.\\n- Add another 2: 4 + 2 = 6.\\n- Add another 2: 6 + 2 = 8.\\n- Add the last 2: 8 + 2 = 10.\\n\\nSo, 2 multiplied by 5 equals 10.\\n\\nAlternatively, I could reverse the numbers to check if multiplication is commutative. That means 5 * 2 should also give me 10. Let me confirm that:\\n\\n5 * 2 = 10.\\n\\nYep, that checks out.\\n\\nI guess another way to think about it is using the distributive property. For example, I can break down the numbers to make the multiplication easier. Let\\'s say I break 5 into 2 + 3:\\n\\n2 * (2 + 3) = (2 * 2) + (2 * 3) = 4 + 6 = 10.\\n\\nThat still gives me the same result.\\n\\nI could also use visual aids to help me understand. Imagine I have two groups of five apples. Each group has five apples, so:\\n\\nGroup 1: Apple, Apple, Apple, Apple, Apple.\\nGroup 2: Apple, Apple, Apple, Apple, Apple.\\n\\nIf I count all the apples together, that\\'s 10 apples in total.\\n\\nAnother method is using the concept of arrays. If I arrange objects in rows and columns, the total number of objects is the product of the number of rows and columns. So, if I have 2 rows of 5 objects each:\\n\\nRow 1: â— â— â— â— â—\\nRow 2: â— â— â— â— â—\\n\\nCounting all the objects gives me 10.\\n\\nI could also use skip counting. Starting from zero, I count by fives twice:\\n\\n5, 10.\\n\\nThat\\'s two fives, which is 10.\\n\\nTo ensure I\\'m not making a mistake, I\\'ll use a calculator or a multiplication chart. Let me visualize a multiplication chart:\\n\\n```\\n   | 1  2  3  4  5\\n-------------------\\n 1 | 1  2  3  4  5\\n 2 | 2  4  6  8 10\\n 3 | 3  6  9 12 15\\n 4 | 4  8 12 16 20\\n 5 | 5 10 15 20 25\\n```\\n\\nLooking at the second row (for 2) and the fifth column (for 5), the intersection is 10.\\n\\nI can also think about real-world examples. For instance, if I have two bags with five marbles each, how many marbles do I have in total? That\\'s 2 * 5 = 10 marbles.\\n\\nAnother way is to use the formula for multiplication:\\n\\n\\\\[ 2 \\\\times 5 = \\\\sum_{i=1}^{5} 2 \\\\]\\n\\nThis means adding 2 five times, which we\\'ve already established equals 10.\\n\\nI could also use exponents, but that might be more complicated for such small numbers. However, just to explore:\\n\\n\\\\[ 2 \\\\times 5 = 2^{\\\\log_2(5)} \\\\]\\n\\nBut this seems unnecessary for such a simple multiplication.\\n\\nTo further verify, I\\'ll use the inverse operation. Division. If 2 * 5 = 10, then dividing 10 by 2 should give me 5, and dividing 10 by 5 should give me 2. Let\\'s check:\\n\\n10 Ã· 2 = 5\\n\\n10 Ã· 5 = 2\\n\\nBoth are correct, which supports that 2 * 5 = 10.\\n\\nAdditionally, thinking about money, if I have two $5 bills, how much money do I have? That\\'s 2 * 5 = $10.\\n\\nI could also use mental math tricks. For example, multiplying by 2 is the same as adding the number to itself:\\n\\n5 + 5 = 10.\\n\\nSo, 2 * 5 = 10.\\n\\nAnother perspective is using the number line. Starting at 0, if I make two jumps of 5 units each:\\n\\n- First jump: 0 + 5 = 5\\n- Second jump: 5 + 5 = 10\\n\\nSo, landing on 10 after two jumps of 5.\\n\\nI might also consider binary representations to understand it computationally. The number 2 in binary is 10, and 5 is 101. Multiplying them in binary:\\n\\n```\\n    10\\n  x 101\\n  ----\\n    10  (this is 2 in decimal)\\n   000  (this is 0 shifted left by one)\\n 10100  (this is 101 shifted left by two)\\n  ----\\n 10100  (which is 20 in decimal)\\n```\\n\\nWait, that gives me 20, which is incorrect. I must have made a mistake here. Let me correct that.\\n\\nActually, multiplying 2 (10 in binary) by 5 (101 in binary) should give me 10 in decimal, which is 1010 in binary. Let me try the multiplication again properly.\\n\\n```\\n     10\\n   x 101\\n   ----\\n     10  (2)\\n   000   (shifted left by one)\\n 1010    (shifted left by two)\\n  ----\\n 1010  (10 in decimal)\\n```\\n\\nAh, that\\'s correct. So, 2 * 5 in binary is indeed 1010, which is 10 in decimal.\\n\\nAnother approach is using algebra. Let me set up an equation:\\n\\nLet x = 2 * 5.\\n\\nTo find x, I can divide both sides by 2:\\n\\nx / 2 = 5\\n\\nThen, multiply both sides by 2:\\n\\nx = 5 * 2\\n\\nWhich again gives x = 10.\\n\\nI could also think about fractions. If I have 2 wholes, each whole divided into 5 parts, how many parts do I have? That would be 2 * 5 = 10 parts.\\n\\nIn terms of geometry, if I have a rectangle with a length of 5 units and a width of 2 units, the area (which is length multiplied by width) would be 10 square units.\\n\\nConsidering the properties of numbers, multiplication is associative and commutative. So, (2 * 5) is the same as (5 * 2), and both equal 10.\\n\\nI could also use the concept of repeated addition with different groupings. For example, adding 2 five times or adding 5 two times both result in 10.\\n\\nAdditionally, thinking about the multiplication table, as I mentioned earlier, helps reinforce that 2 * 5 = 10.\\n\\nI might also use real-life scenarios to solidify my understanding. For example, if I have two dogs, and each dog has five bones, how many bones are there in total? That\\'s 2 * 5 = 10 bones.\\n\\nAnother way is to use the distributive property with different numbers. For instance, 2 * (1 + 4) = (2 * 1) + (2 * 4) = 2 + 8 = 10.\\n\\nI could also use algebraic expressions. Let me set up an expression where 2 * 5 is part of a larger equation. For example:\\n\\nIf 2 * x = 10, then x = 10 / 2 = 5.\\n\\nThis shows that 2 * 5 = 10.\\n\\nFurthermore, using the concept of inverse operations, if I know that division is the inverse of multiplication, then dividing 10 by 2 gives me 5, which confirms that 2 * 5 = 10.\\n\\nI could also use number bonds. Knowing that 5 is composed of 2 and 3, I can think of 2 * 5 as 2 * (2 + 3) = 4 + 6 = 10.\\n\\nAnother method is using the area model. If I create a rectangle where one side is 2 and the other is 5, the area of the rectangle represents the product, which is 10.\\n\\nAdditionally, thinking about money again, if I have five $2 bills, how much do I have? That\\'s 5 * 2 = $10.\\n\\nI could also use exponents creatively. Knowing that 5 is 5^1 and 2 is 2^1, but that doesn\\'t directly help here. However, using exponent rules, 2^1 * 5^1 = 10^1 = 10.\\n\\nAnother perspective is through the lens of set theory. If I have two sets, one with five elements and another with two elements, the Cartesian product\\'s cardinality is 2 * 5 = 10.\\n\\nI might also consider the English words. \"Two fives\" are ten. In time, five minutes twice is ten minutes.\\n\\nIn summary, through various methodsâ€”repeated addition, distributive property, real-world examples, binary multiplication, algebra, geometry, and moreâ€”it consistently shows that 2 multiplied by 5 equals 10. This redundancy across different mathematical concepts reinforces the correctness of the answer.\\n'}, response_metadata={'token_usage': {'completion_tokens': 2102, 'prompt_tokens': 431, 'total_tokens': 2533, 'completion_time': 7.643636364, 'prompt_time': 0.027650556, 'queue_time': 0.202421972, 'total_time': 7.67128692}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1e9dd3a5-8f36-412a-85cb-2df468c9c07a-0', usage_metadata={'input_tokens': 431, 'output_tokens': 2102, 'total_tokens': 2533})]}})\n",
            "----\n",
            "((), {'coder': {'messages': [HumanMessage(content='The result of multiplying 2 by 5 is 10. This can be understood through various methods such as repeated addition, distributive property, real-world examples, and binary multiplication, all consistently leading to the same result.\\n\\n**Answer:** 10', additional_kwargs={}, response_metadata={}, name='coder')]}})\n",
            "----\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-83-630522252.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"What's the 2*5? use appropriate  tool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2532\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2534\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2535\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2536\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-74-3194298996.py\u001b[0m in \u001b[0;36msupervisor_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msystem_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRouter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3042\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5432\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5433\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5434\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5435\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    979\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 results.append(\n\u001b[0;32m--> 799\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    800\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1046\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_groq/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         }\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         )\n\u001b[0;32m-> 1232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}"
          ]
        }
      ],
      "source": [
        "for s in app.stream({\"messages\": [(\"user\", \"What's the 2*5? use appropriate  tool\")]}, subgraphs=True):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb76b2d",
      "metadata": {
        "id": "2eb76b2d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}